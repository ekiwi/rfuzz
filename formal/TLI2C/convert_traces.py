#!/usr/bin/env python3
import argparse, tqdm, shutil, os, glob, re, json
from pathlib import Path


def parse():
  parser = argparse.ArgumentParser(description='Convert risc-v mini traces generated by sby to binary inputs comparable to what is produced by the fuzzer.')
  parser.add_argument('--in', dest='input', help='input folder from symbiyosys', required=True)
  parser.add_argument('--to', help='output folder', required=True)
  parser.add_argument('--overwrite', help='overwrite the output directory', action='store_true')
  args = parser.parse_args()
  return Path(args.input), Path(args.to), args.overwrite

def create_output_dir(to, overwrite: bool):
  if os.path.exists(to):
    if overwrite:
      shutil.rmtree(to)
    else:
      raise RuntimeError(f"{to} already exists. Use `--overwrite` to allow it to be overwritten.")
  os.mkdir(to)

_inputs_re = re.compile(r"io_inputs <?= \d+'b([01]+);")

def find_input_assignments(filename) -> list[str]:
  res = []
  with open(filename) as ff:
    for line in ff.readlines():
      m = _inputs_re.search(line)
      if m is not None:
        data = m.group(1)
        res.append(data)
  return res

align = 8
def bits_to_size(bits):
  bytes = (bits + 7) // 8
  words = (bytes + align - 1) // align
  return words * align



def to_bytes(input_bytes: int, value: str) -> list[int]:
  bit_count = len(value)
  assert input_bytes == bits_to_size(bit_count)
  # assign dut_io_inputs = input_bytes[191:27]; // @[VerilatorHarness.scala 108:23]
  ivalue = int(value, 2) << ((input_bytes * 8) - bit_count)
  assert ivalue >= 0

  # top->io_input_bytes_{0: <3}  = input[{0: >3}];
  # wire [191:0] input_bytes = {io_input_bytes_0,io_input_bytes_1,io_input_bytes_2, ...
  bbs = []
  for ii in range(input_bytes):
    bbs = [ivalue & 0xff] + bbs
    ivalue >>= 8
  return bbs


def parse_time(time: str) -> dict:
  parts = time.split(":")
  assert len(parts) == 3, time
  minutes = int(parts[0]) * 60 + int(parts[1])
  seconds = minutes * 60 + int(parts[2])
  return {'secs': seconds, 'nanos': 0}

def inputs_to_entry(inputs: list[str], ii: int, step: int, time: str) -> dict:
  discovery_time = parse_time(time)
  entry = {
    'id': ii,
    'discovered_after': discovery_time,
    # bogus default values to make the analysis script happy
    'is_valid': True,
    'not_covered': [],
    'lineage': None,
  }
  # find out how many bits are in one input
  input_bits = len(inputs[0])
  # determine how many bytes
  input_size = bits_to_size(input_bits)

  # skip first 2 entries as they represent the value during reset + meta reset
  iis = []
  for ii in inputs[1:]:
    iis += to_bytes(input_size, ii)
  entry['inputs'] = iis


  return  { 'entry' : entry, 'stats': {} }


_step_re = re.compile(r"in step (\d+)")
_writing_trace_re = re.compile(r"(\d:\d+:\d+)\s+Writing trace to Verilog testbench: ([^\n]+)")

def parse_log(filename: Path):
  step = 0
  traces = []
  with open(filename) as ff:
    for line in ff.readlines():
      m = _step_re.search(line)
      if m is not None:
        step = int(m.group(1))
      m = _writing_trace_re.search(line)
      if m is not None:
        t = (step, m.group(1), m.group(2).strip())
        traces.append(t)
  return traces

def convert(inp, to):
  assert inp.is_dir()
  traces = parse_log(inp / "logfile.txt")

  ii = 0
  for step, time, filename in tqdm.tqdm(traces):
    mem = find_input_assignments(inp / filename)
    entry = inputs_to_entry(mem, ii, step, time)
    ii += 1
    basename = os.path.basename(filename)
    with open(to / ("entry_" + basename + ".json"), 'w') as ff:
      json.dump(entry, ff)

def main():
  inp, to, overwrite = parse()
  create_output_dir(to, overwrite)
  convert(inp, to)


if __name__ == "__main__":
  main()
